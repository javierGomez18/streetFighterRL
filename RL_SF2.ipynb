{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c59353-82f8-4376-8ae2-e1662bbe8976",
   "metadata": {},
   "source": [
    "# Agente Street Fighter 2 \n",
    "\n",
    "## Configurar Entorno\n",
    "\n",
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28dbc0a7-8883-4eea-b1c7-e30a983bcdcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtramos los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Forzar uso CPU en caso de dispones GPU en el PC\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# instalar librerias\n",
    "#!pip3 install gym==0.17.2 gym-retro==0.8.0 --user\n",
    "#!pip3 install tensorflow==2.3.0\n",
    "#!pip3 install keras-rl2==1.0.4 keras==2.8.0\n",
    "\n",
    "# Import retro para crear el entorno Street Fighter a partir de la ROM\n",
    "import retro\n",
    "\n",
    "# Import Time para relentizar el juego\n",
    "import time\n",
    "\n",
    "# Import Clase base del entorno para hacer wrapper\n",
    "from gym import Env\n",
    "\n",
    "# Import los shapes espaciales para el entorno\n",
    "from gym.spaces import MultiBinary, Box\n",
    "\n",
    "# Import numpy para calcular el frame delta\n",
    "import numpy as np\n",
    "\n",
    "# Import opencv para aplicar la escala de grises\n",
    "import cv2\n",
    "\n",
    "# Import matplotlib para visualizar la imagen\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import generación modelo\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import average\n",
    "\n",
    "# Construcción del agente\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2cad5-6478-4389-95f9-f4cdde45125f",
   "metadata": {},
   "source": [
    "### Prueba entorno Street Fighter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff766e-2eb8-4ba4-b27a-4546cd3aad95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "for game in range(1):\n",
    "    while not done:\n",
    "        if(done):\n",
    "            obs = env.reset()\n",
    "\n",
    "        env.render()\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        #time.sleep(0.00001)\n",
    "        print(reward)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af572dbd-0df2-43f4-baed-45e437ceba9d",
   "metadata": {},
   "source": [
    "### Configuración del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d15c64-278d-4ffd-b195-6e71bf8870a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una clase para definir el entorno de SF2\n",
    "class StreetFighter(Env):\n",
    "    def __init__(self, state):\n",
    "        super().__init__()\n",
    "        # Especificar el espacio de acciones y el espacio de observaciones\n",
    "        self.observation_space = Box(low=0, \n",
    "                                     high=255, \n",
    "                                     shape=(84, 84, 1), \n",
    "                                     dtype=np.uint8)\n",
    "        state\n",
    "        # Instanciar el entorno\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis',\n",
    "                               state=state,\n",
    "                               use_restricted_actions=retro.Actions.DISCRETE)\n",
    "        \n",
    "        self.action_space = MultiBinary(self.game.action_space.n)\n",
    "                \n",
    "    def reset(self):\n",
    "        \n",
    "        # Devolvemos el primer frame\n",
    "        obs = self.game.reset()\n",
    "         \n",
    "        # Preprocess\n",
    "        obs = self.preprocess(obs)\n",
    "        self.previous_frame = obs\n",
    "        \n",
    "        # Inicializar atributo para la diferencia de la puntuación\n",
    "        self.score = 0\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def preprocess(self, observation):\n",
    "        # Aplicamos el redimensionado del frame y el escalado de grises\n",
    "        # Escalado de grises\n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        # Redimensionado del frame\n",
    "        resize = cv2.resize(gray, (84,84), interpolation=cv2.INTER_CUBIC)\n",
    "        # Añadir el valor de los canales\n",
    "        channel = np.reshape(resize, (84,84,1))\n",
    "        \n",
    "        return channel\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Realizar una acción\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        \n",
    "        # Procesamos la observación\n",
    "        obs = self.preprocess(obs)\n",
    "        \n",
    "        # Calcular frame delta (Variación en frame anterior y actual)\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs\n",
    "        \n",
    "        # Adaptamos la función de recompensa\n",
    "        reward = info['score'] - self.score\n",
    "        self.score = info['score']\n",
    "        \n",
    "        return frame_delta, reward, done, info\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da49428-57f3-4dcd-aff4-ad0cbc32a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\n",
    "    \"Champion.Level1.RyuVsGuile\",\n",
    "    \"Champion.Level2.RyuVsBlanka\",\n",
    "    \"Champion.Level3.RyuVsRyu\",\n",
    "    \"Champion.Level4.RyuVsKen\",\n",
    "    \"Champion.Level5.RyuVsChunLi\",\n",
    "    \"Champion.Level6.RyuVsZangief\",\n",
    "    \"Champion.Level8.RyuVsDhalsim\",\n",
    "    \"Champion.Level9.RyuVsHonda\",\n",
    "    \"Champion.Level11.RyuVsBalrog\",\n",
    "    \"Champion.Level13.RyuVsVega\",\n",
    "    \"Champion.Level14.RyuVsSagat\",\n",
    "    \"Champion.Level15.RyuVsBison\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146159c5-b9a8-4d7f-ba7f-a7476d126778",
   "metadata": {},
   "source": [
    "## Creación del modelo\n",
    "\n",
    "La arquitectura de la DQN se compondrá de dos partes:\n",
    " * Visión por computación: reconocimiento de imágenes.\n",
    " * Regresión: determinar los valores Q de cada acción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f12119-2dec-4ded-b84e-bae049608fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la arquitectura de la DQN\n",
    "def build_DQN(input_shape, output_shape):\n",
    "    height, width, channels = input_shape\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Bloque Capas convolucionales\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(8,8), strides=(4,4), activation=\"relu\", input_shape=(1, height, width, channels)))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(4,4), strides=(2,2), activation=\"relu\"))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Bloque Capas lineales para determinar el Q-valor \n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(units=output_shape, activation='linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2115e47-91e5-46f7-ad76-ad17815710e3",
   "metadata": {},
   "source": [
    "## Creación del Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c798bece-2f02-4465-b353-13f6ee236742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del Agente\n",
    "def build_DQN_Agent(model, actions):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)\n",
    "    memory = SequentialMemory(limit=10000, window_length=1)\n",
    "    agent = DQNAgent(model=model,\n",
    "                     memory=memory,\n",
    "                     policy=policy,\n",
    "                     enable_dueling_network=True,\n",
    "                     dueling_type='avg',\n",
    "                     nb_actions=actions,\n",
    "                     nb_steps_warmup=1000)\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834d5540-bf1c-46ce-b8cf-0a67d9d07477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del Agente\n",
    "def load_DQN_Agent(agent, actions):\n",
    "    policy = agent.policy\n",
    "    memory = agent.memory\n",
    "    agent = DQNAgent(model=agent.model,\n",
    "                     memory=memory,\n",
    "                     policy=policy,\n",
    "                     enable_dueling_network=True,\n",
    "                     dueling_type='avg',\n",
    "                     nb_actions=actions,\n",
    "                     nb_steps_warmup=1000)\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dd282-fed3-487b-a334-8eda11c52361",
   "metadata": {},
   "source": [
    "### Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069cc8c6-bb32-4b34-a89b-7230ef2c3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_agent(agent_toSave, countModel, path):\n",
    "    \n",
    "    agent_pathName = path + '/agent_'+str(countModel)+'.h5f'\n",
    "    print(agent_pathName)\n",
    "    agent_toSave.save_weights(agent_pathName, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c86a1e-e5a0-413d-bac8-68eaa3cc2e25",
   "metadata": {},
   "source": [
    "### Entrenamiento del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f53bd38-fa8d-4ea4-9603-4c00689751bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DQN_agent(states_train, num_iteration, agent, lr):\n",
    "    \n",
    "    score_baseModel = 0\n",
    "    \n",
    "    if(num_iteration > 1):\n",
    "        loadModel_path = \"./test/historyModel/iter\"+str(num_iteration-1)+\"/agent_1.h5f\"\n",
    "\n",
    "        env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "\n",
    "        agent.load_weights(loadModel_path)\n",
    "\n",
    "        score_baseModel = list(agent.test(env, nb_episodes=1, visualize=True).history.values())[0][0]\n",
    "\n",
    "        env.close()\n",
    "        del env\n",
    "        \n",
    "    for state in states:\n",
    "        for i in range(1,4):\n",
    "            \n",
    "            path = \"./train/\"+state.split('.')[2] \n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            \n",
    "            env = StreetFighter(state)\n",
    "            \n",
    "            if(num_iteration == 1):\n",
    "\n",
    "                model = build_DQN(env.observation_space.shape, env.action_space.n)\n",
    "                agent = build_DQN_Agent(model, env.action_space.n)\n",
    "            else:\n",
    "                agent.load_weights(loadModel_path)\n",
    "            \n",
    "            agent.compile(Adam(), metrics=['mae'])\n",
    "            agent.fit(env, nb_steps=20000, nb_max_episode_steps=20000, visualize=False, verbose=2)\n",
    "\n",
    "            save_agent(agent,i,path)\n",
    "\n",
    "            env.close()\n",
    "            del env\n",
    "    return agent, score_baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56dfab48-9966-45c9-b2fb-99f63e27c4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_agent(states_train, num_iteration, agent, lr):\n",
    "    \n",
    "    score_baseModel = 0\n",
    "    \n",
    "    if(num_iteration > 1):\n",
    "        loadModel_path = \"./test/historyModel/iter\"+str(num_iteration-1)+\"/agent_1.h5f\"\n",
    "\n",
    "        env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "\n",
    "        agent.load_weights(loadModel_path)\n",
    "\n",
    "        score_baseModel = list(agent.test(env, nb_episodes=1, visualize=True).history.values())[0][0]\n",
    "\n",
    "        env.close()\n",
    "        del env\n",
    "    \n",
    "    elif(num_iteration == 1):\n",
    "                \n",
    "        del agent\n",
    "        model = build_DQN(env.observation_space.shape, env.action_space.n)\n",
    "        agent = build_DQN_Agent(model, env.action_space.n)\n",
    "\n",
    "    for state in states:\n",
    "        for i in range(1,2):\n",
    "            \n",
    "            path = \"./train/\"+state.split('.')[2] \n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            \n",
    "            env = StreetFighter(state)\n",
    "            \n",
    "            agent.compile(Adam(), metrics=['mae'])\n",
    "            agent.fit(env, nb_steps=50000, nb_max_episode_steps=50000, visualize=False, verbose=2)\n",
    "\n",
    "            env.close()\n",
    "            del env\n",
    "            \n",
    "            isBetter_agent, score_newModel = test_agent(state, agent, score_baseModel)\n",
    "            \n",
    "            if(isBetter_agent):\n",
    "                save_agent(agent,i,path)\n",
    "                score_baseModel = score_newModel\n",
    "            else:\n",
    "                agent.load_weights(loadModel_path)\n",
    "            \n",
    "    return agent, score_baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60ce39f-625e-4a18-b2c6-69cc8f6fa67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14308\\3659701284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStreetFighter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Champion.Level1.RyuVsGuile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./train/RyuVsDhalsim/agent_3.h5f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "models_weights = []\n",
    "\n",
    "env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "\n",
    "agent.load_weights(\"./train/RyuVsDhalsim/agent_3.h5f\")\n",
    "agent.test(env, nb_episodes=1, visualize=True)\n",
    "\n",
    "models_weights.append(agent.model.get_weights())\n",
    "\n",
    "save_path=\"./test/historyModel/iter8\"\n",
    "save_agent(agent, 1, save_path)\n",
    "\n",
    "agent.load_weights(save_path+\"/agent_1.h5f\")\n",
    "agent.test(env, nb_episodes=1, visualize=True)\n",
    "\n",
    "\n",
    "env.close()\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b7a7b4-6229-44c7-9563-5799afff3d22",
   "metadata": {},
   "source": [
    "## Test del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495c95be-4fd4-4aa1-a3db-f4534ad1ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_modelFinal(states, model_states, num_iteration, agent):\n",
    "    \n",
    "    models = []\n",
    "    saveModel_path = \"./test/historyModel\"\n",
    "    \n",
    "    if not os.path.exists(saveModel_path):\n",
    "        os.mkdir(saveModel_path)\n",
    "    if not os.path.exists(saveModel_path+\"/iter\"+str(num_iteration)):   \n",
    "        os.mkdir(saveModel_path+\"/iter\"+str(num_iteration))\n",
    "            \n",
    "    for model in model_states.items():\n",
    "        models.append(model[1])\n",
    "    \n",
    "    model_final = np.mean(models, axis=0)\n",
    "\n",
    "    env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "\n",
    "    agent.model.set_weights(model_final)\n",
    "\n",
    "    print(\"\\n\\n\\nFinal Test\")\n",
    "\n",
    "    score = agent.test(env, nb_episodes=1, visualize=True)\n",
    "\n",
    "    save_agent(agent,1,saveModel_path+\"/iter\"+str(num_iteration))\n",
    "\n",
    "    env.close()\n",
    "    del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639a3347-8979-4934-b095-929d6562f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(state, agent, score_min):\n",
    "    isBetter_agent = False\n",
    "    env = StreetFighter(states[0])\n",
    "    \n",
    "    score = agent.test(env, nb_episodes=1, visualize=False)\n",
    "    \n",
    "    if(list(score.history.values())[0][0] > score_min):\n",
    "        isBetter_agent = True\n",
    "    else:\n",
    "        score = score_min\n",
    "        \n",
    "    env.close()\n",
    "    del env\n",
    "    return isBetter_agent,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9803a14-8eb1-413b-a984-1b7f81d9aba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_DQN_agent(states_test, num_iteration, min_value, agent):\n",
    "    model_states = {}\n",
    "    \n",
    "    print(\"Test Iteración \"+str(num_iteration))\n",
    "    \n",
    "    for state in states_test:\n",
    "        \n",
    "        model_path = \"./train/\"+state.split('.')[2]\n",
    "        models = []\n",
    "        key_score = state.split('.')[2]\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            os.mkdir(model_path)\n",
    "        \n",
    "        for i in range(1,2):\n",
    "            agent_path = model_path+'/agent_'+str(i)+'.h5f'\n",
    "\n",
    "            env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "            \n",
    "            agent.load_weights(agent_path)\n",
    "                        \n",
    "            score = agent.test(env, nb_episodes=1, visualize=False)\n",
    "                                        \n",
    "            if((list(score.history.values())[0][0] > min_value)):           \n",
    "                models.append(agent.model.get_weights())\n",
    "            \n",
    "            env.close()\n",
    "            del env\n",
    "        if(len(models)>0):\n",
    "            model_merged = np.mean(models, axis=0)\n",
    "            model_states[key_score] = model_merged \n",
    "    if(len(models)>0):\n",
    "        for model in model_states.items():\n",
    "\n",
    "            saveModel_path = \"./test/\"+model[0]\n",
    "\n",
    "            if not os.path.exists(saveModel_path):\n",
    "                os.mkdir(saveModel_path)\n",
    "                os.mkdir(saveModel_path+\"/iter\"+str(num_iteration))\n",
    "\n",
    "            if os.path.isdir(saveModel_path+\"/iter\"+str(num_iteration)):\n",
    "\n",
    "                agent.model.set_weights(model_states[model[0]])\n",
    "\n",
    "                env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "\n",
    "                score = agent.test(env, nb_episodes=1, visualize=False)\n",
    "\n",
    "                save_agent(agent,1,saveModel_path+\"/iter\"+str(num_iteration))\n",
    "\n",
    "                print(\"El modelo testeado del estado {}\".format(model[0])\n",
    "                      +\"\\nse ha almacenado en el path {}\".format(saveModel_path))\n",
    "\n",
    "                env.close()\n",
    "                del env\n",
    "        generate_modelFinal(states_test, model_states, num_iteration, agent)\n",
    "    else:\n",
    "        print(\"No se ha generado un modelo con puntuación mayor a {} en fase de test\".format(min_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158dc4f-4967-4010-8c83-7f59b43f281f",
   "metadata": {},
   "source": [
    "## Generación del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cf4d626-84b8-459c-84d1-98afb209cbe7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      " 1000/1000: episode: 1, duration: 6.946s, episode steps: 1000, steps per second: 144, episode reward: 1500.000, mean reward:  1.500 [ 0.000, 500.000], mean action: 62.300 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 6.947 seconds\n",
      "Iniciando entrenamiento número 8\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 183400.000, steps: 30643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000021F58B42CA8>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000021F944A6F98; to 'Win32Window' at 0x0000021F944AFF88>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20000 steps ...\n",
      "  5158/20000: episode: 1, duration: 242.412s, episode steps: 5158, steps per second:  21, episode reward: 20700.000, mean reward:  4.013 [ 0.000, 10000.000], mean action: 61.945 [0.000, 125.000],  loss: 4499.412228, mae: 125.958039, mean_q: 215.297339, mean_eps: 0.722890\n",
      "  9630/20000: episode: 2, duration: 241.054s, episode steps: 4472, steps per second:  19, episode reward: 4100.000, mean reward:  0.917 [ 0.000, 500.000], mean action: 62.786 [0.000, 125.000],  loss: 714.028663, mae: 101.891900, mean_q: 159.603743, mean_eps: 0.334585\n",
      " 13934/20000: episode: 3, duration: 230.239s, episode steps: 4304, steps per second:  19, episode reward: 2800.000, mean reward:  0.651 [ 0.000, 1000.000], mean action: 58.232 [0.000, 125.000],  loss: 370.331981, mae: 108.773868, mean_q: 155.692405, mean_eps: 0.101435\n",
      "done, took 1044.096 seconds\n",
      "./train/RyuVsRyu/agent_1.h5f\n",
      "Training for 20000 steps ...\n",
      "  3712/20000: episode: 1, duration: 165.965s, episode steps: 3712, steps per second:  22, episode reward: 1500.000, mean reward:  0.404 [ 0.000, 500.000], mean action: 61.382 [0.000, 125.000],  loss: 753.090701, mae: 122.171663, mean_q: 195.065297, mean_eps: 0.787960\n",
      "  8166/20000: episode: 2, duration: 242.527s, episode steps: 4454, steps per second:  18, episode reward: 1900.000, mean reward:  0.427 [ 0.000, 500.000], mean action: 62.800 [0.000, 125.000],  loss: 567.822034, mae: 112.940071, mean_q: 165.111098, mean_eps: 0.465535\n",
      " 12628/20000: episode: 3, duration: 244.193s, episode steps: 4462, steps per second:  18, episode reward: 3400.000, mean reward:  0.762 [ 0.000, 1000.000], mean action: 58.677 [0.000, 125.000],  loss: 649.525348, mae: 125.750353, mean_q: 178.914319, mean_eps: 0.133941\n",
      " 16784/20000: episode: 4, duration: 227.499s, episode steps: 4156, steps per second:  18, episode reward: 1700.000, mean reward:  0.409 [ 0.000, 500.000], mean action: 63.251 [0.000, 125.000],  loss: 621.255982, mae: 132.541486, mean_q: 183.415486, mean_eps: 0.100000\n",
      "done, took 1057.767 seconds\n",
      "./train/RyuVsRyu/agent_2.h5f\n",
      "Training for 20000 steps ...\n",
      "  4684/20000: episode: 1, duration: 215.168s, episode steps: 4684, steps per second:  22, episode reward: 4000.000, mean reward:  0.854 [ 0.000, 1000.000], mean action: 60.977 [0.000, 125.000],  loss: 642.720159, mae: 121.926754, mean_q: 183.613589, mean_eps: 0.744220\n",
      "  8810/20000: episode: 2, duration: 226.884s, episode steps: 4126, steps per second:  18, episode reward: 2600.000, mean reward:  0.630 [ 0.000, 500.000], mean action: 63.257 [0.000, 125.000],  loss: 2671.661885, mae: 116.612758, mean_q: 166.119258, mean_eps: 0.392815\n",
      " 13414/20000: episode: 3, duration: 252.319s, episode steps: 4604, steps per second:  18, episode reward: 1200.000, mean reward:  0.261 [ 0.000, 500.000], mean action: 65.175 [0.000, 125.000],  loss: 495.489104, mae: 115.903885, mean_q: 161.242793, mean_eps: 0.113853\n",
      " 17576/20000: episode: 4, duration: 231.410s, episode steps: 4162, steps per second:  18, episode reward: 2100.000, mean reward:  0.505 [ 0.000, 500.000], mean action: 65.546 [0.000, 125.000],  loss: 314.683457, mae: 118.376665, mean_q: 160.657107, mean_eps: 0.100000\n",
      "done, took 1059.089 seconds\n",
      "./train/RyuVsRyu/agent_3.h5f\n",
      "Training for 20000 steps ...\n",
      " 11264/20000: episode: 1, duration: 594.978s, episode steps: 11264, steps per second:  19, episode reward: 37000.000, mean reward:  3.285 [ 0.000, 10000.000], mean action: 63.083 [0.000, 125.000],  loss: 2918.551910, mae: 125.739974, mean_q: 188.846330, mean_eps: 0.455120\n",
      " 14145/20000: episode: 2, duration: 153.428s, episode steps: 2881, steps per second:  19, episode reward: 2700.000, mean reward:  0.937 [ 0.000, 500.000], mean action: 64.672 [0.000, 125.000],  loss: 595.596114, mae: 115.872229, mean_q: 163.550553, mean_eps: 0.100000\n",
      "done, took 1058.671 seconds\n",
      "./train/RyuVsHonda/agent_1.h5f\n",
      "Training for 20000 steps ...\n",
      " 14552/20000: episode: 1, duration: 761.385s, episode steps: 14552, steps per second:  19, episode reward: 34800.000, mean reward:  2.391 [ 0.000, 1500.000], mean action: 63.094 [0.000, 125.000],  loss: 5753.254910, mae: 128.817411, mean_q: 185.962330, mean_eps: 0.368954\n",
      "done, took 1063.741 seconds\n",
      "./train/RyuVsHonda/agent_2.h5f\n",
      "Training for 20000 steps ...\n",
      "  6155/20000: episode: 1, duration: 306.037s, episode steps: 6155, steps per second:  20, episode reward: 17800.000, mean reward:  2.892 [ 0.000, 1500.000], mean action: 63.050 [0.000, 125.000],  loss: 3831.172257, mae: 134.632868, mean_q: 219.683006, mean_eps: 0.678025\n",
      " 12463/20000: episode: 2, duration: 351.973s, episode steps: 6308, steps per second:  18, episode reward: 28500.000, mean reward:  4.518 [ 0.000, 10000.000], mean action: 56.685 [0.000, 125.000],  loss: 11869.521521, mae: 115.776025, mean_q: 180.685034, mean_eps: 0.205494\n",
      "done, took 1066.021 seconds\n",
      "./train/RyuVsHonda/agent_3.h5f\n",
      "Training for 20000 steps ...\n",
      " 20000/20000: episode: 1, duration: 1049.670s, episode steps: 20000, steps per second:  19, episode reward: 64800.000, mean reward:  3.240 [ 0.000, 10000.000], mean action: 60.684 [0.000, 125.000],  loss: 4126.372656, mae: 129.831653, mean_q: 185.921723, mean_eps: 0.291831\n",
      "done, took 1049.697 seconds\n",
      "./train/RyuVsGuile/agent_1.h5f\n",
      "Training for 20000 steps ...\n",
      " 12911/20000: episode: 1, duration: 670.763s, episode steps: 12911, steps per second:  19, episode reward: 57800.000, mean reward:  4.477 [ 0.000, 10000.000], mean action: 58.317 [0.000, 125.000],  loss: 4202.462601, mae: 122.127241, mean_q: 184.943481, mean_eps: 0.406011\n",
      " 19803/20000: episode: 2, duration: 376.643s, episode steps: 6892, steps per second:  18, episode reward: 27300.000, mean reward:  3.961 [ 0.000, 10000.000], mean action: 63.072 [0.000, 125.000],  loss: 2073.296762, mae: 114.922537, mean_q: 166.610792, mean_eps: 0.100000\n",
      "done, took 1058.190 seconds\n",
      "./train/RyuVsGuile/agent_2.h5f\n",
      "Training for 20000 steps ...\n",
      " 20000/20000: episode: 1, duration: 1336.495s, episode steps: 20000, steps per second:  15, episode reward: 126700.000, mean reward:  6.335 [ 0.000, 10000.000], mean action: 64.522 [0.000, 125.000],  loss: 6014.363844, mae: 122.866568, mean_q: 195.264762, mean_eps: 0.291831\n",
      "done, took 1336.580 seconds\n",
      "./train/RyuVsGuile/agent_3.h5f\n",
      "Iniciando fase de test del entrenamiento número 8\n",
      "Test Iteración 8\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 4200.000, steps: 5014\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 41800.000, steps: 10099\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 22200.000, steps: 8475\n",
      "No se ha generado un modelo con puntuación mayor a 183400.0 en fase de test\n",
      "Finalizada fase de test del entrenamiento número 8\n"
     ]
    }
   ],
   "source": [
    "env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "model = build_DQN(env.observation_space.shape, env.action_space.n)\n",
    "agent = build_DQN_Agent(model, env.action_space.n)\n",
    "agent.compile(Adam(), metrics=['mae'])\n",
    "agent.fit(env, nb_steps=1000, nb_max_episode_steps=1000, visualize=False, verbose=2)\n",
    "env.close()\n",
    "del env\n",
    "\n",
    "print(\"Iniciando entrenamiento número 8\")\n",
    "\n",
    "agent,score_min = train_DQN_agent(states, 8, agent, 1e-7)\n",
    "\n",
    "print(\"Iniciando fase de test del entrenamiento número 8\")\n",
    "test_DQN_agent(states, 8, score_min, agent)\n",
    "\n",
    "print(\"Finalizada fase de test del entrenamiento número 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8f6110-9f17-4386-8d37-58ebf18d407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2928bba5-d755-4a6e-8a49-787f50af7c10",
   "metadata": {},
   "source": [
    "## Analisis de la evolución del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac5cf45-9843-41d3-9763-2262707f329c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de la evolución del agente: \n",
      "\n",
      "\n",
      "\n",
      "Training for 1000 steps ...\n",
      "WARNING:tensorflow:From C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " 1000/1000: episode: 1, duration: 3.704s, episode steps: 1000, steps per second: 270, episode reward: 2500.000, mean reward:  2.500 [ 0.000, 1000.000], mean action: 62.007 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 3.709 seconds\n",
      "Agente generado en la iteración 1.\n",
      "\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 16100.000, steps: 7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000024BD2943B88>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000024BD295D598; to 'Win32Window' at 0x0000024BD1FB0188>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      " 1000/1000: episode: 1, duration: 4.029s, episode steps: 1000, steps per second: 248, episode reward: 2300.000, mean reward:  2.300 [ 0.000, 1000.000], mean action: 61.381 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 4.032 seconds\n",
      "Agente generado en la iteración 2.\n",
      "\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 15400.000, steps: 7341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000024BD2943B88>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000024BD97E9F98; to 'Win32Window' at 0x0000024BDF6384C8>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      " 1000/1000: episode: 1, duration: 3.886s, episode steps: 1000, steps per second: 257, episode reward: 600.000, mean reward:  0.600 [ 0.000, 500.000], mean action: 62.206 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 3.890 seconds\n",
      "Agente generado en la iteración 3.\n",
      "\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 33800.000, steps: 9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000024BD2943B88>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000024BDF6281D8; to 'Win32Window' at 0x0000024BD97E0788>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      " 1000/1000: episode: 1, duration: 4.002s, episode steps: 1000, steps per second: 250, episode reward: 2500.000, mean reward:  2.500 [ 0.000, 1000.000], mean action: 62.592 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 4.005 seconds\n",
      "Agente generado en la iteración 4.\n",
      "\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 35900.000, steps: 11317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000024BD2943B88>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000024BE0011408; to 'Win32Window' at 0x0000024BE0000988>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      " 1000/1000: episode: 1, duration: 4.061s, episode steps: 1000, steps per second: 246, episode reward: 3200.000, mean reward:  3.200 [ 0.000, 1000.000], mean action: 64.689 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 4.064 seconds\n",
      "Agente generado en la iteración 5.\n",
      "\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 47200.000, steps: 12560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000024BD2943B88>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000024BDF463AE8; to 'Win32Window' at 0x0000024BE21AEEC8>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      " 1000/1000: episode: 1, duration: 3.961s, episode steps: 1000, steps per second: 252, episode reward: 500.000, mean reward:  0.500 [ 0.000, 500.000], mean action: 61.742 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 3.964 seconds\n",
      "Agente generado en la iteración 6.\n",
      "\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 82600.000, steps: 9228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000024BD2943B88>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000024BE21A3A98; to 'Win32Window' at 0x0000024BE21A0D08>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      " 1000/1000: episode: 1, duration: 4.201s, episode steps: 1000, steps per second: 238, episode reward: 2000.000, mean reward:  2.000 [ 0.000, 1000.000], mean action: 61.488 [0.000, 125.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "done, took 4.204 seconds\n",
      "Agente generado en la iteración 7.\n",
      "\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 183400.000, steps: 30643\n"
     ]
    }
   ],
   "source": [
    "print('Análisis de la evolución del agente: \\n\\n\\n')\n",
    "for i in range(1,8):\n",
    "    \n",
    "    path_agent = \"./test/historyModel/iter\"+str(i)+\"/agent_1.h5f\"\n",
    "    \n",
    "    env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "    model = build_DQN(env.observation_space.shape, env.action_space.n)\n",
    "    agent = build_DQN_Agent(model, env.action_space.n)\n",
    "    agent.compile(Adam(), metrics=['mae'])\n",
    "    agent.fit(env, nb_steps=1000, nb_max_episode_steps=1000, visualize=False, verbose=2)\n",
    "    env.close()\n",
    "    del env\n",
    "    \n",
    "    print('Agente generado en la iteración {}.\\n'.format(i))\n",
    "    env = StreetFighter(\"Champion.Level1.RyuVsGuile\")\n",
    "    \n",
    "    agent.load_weights(path_agent)\n",
    "    \n",
    "    agent.test(env, nb_episodes=1, visualize=True)\n",
    "    \n",
    "    del agent\n",
    "    env.close()\n",
    "    del env\n",
    "    \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f159f628-cd61-4299-8eef-f71d40bdfd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x000001BF9BCB1678>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 379, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 375, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\javie\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\javie\\anaconda3\\envs\\Python37_RL_streetFighter\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x000001BF9BCC6408; to 'Win32Window' at 0x000001BF9B546BC8>,)\n"
     ]
    }
   ],
   "source": [
    "env = StreetFighter(\"Champion.Level1.RyuVsGuile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8232947e-b9fd-4674-bd9b-c1a5b3d61ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 16100.000, steps: 7058\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 35900.000, steps: 11317\n",
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 183400.000, steps: 30643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bf9e6f3908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(10)\n",
    "path_agent = \"./test/historyModel/iter1/agent_1.h5f\"\n",
    "agent.load_weights(path_agent)\n",
    "    \n",
    "agent.test(env, nb_episodes=1, visualize=True)\n",
    "\n",
    "path_agent = \"./test/historyModel/iter4/agent_1.h5f\"\n",
    "agent.load_weights(path_agent)\n",
    "    \n",
    "agent.test(env, nb_episodes=1, visualize=True)\n",
    "\n",
    "path_agent = \"./test/historyModel/iter7/agent_1.h5f\"\n",
    "agent.load_weights(path_agent)\n",
    "    \n",
    "agent.test(env, nb_episodes=1, visualize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6228a-7587-4a4b-9ac0-6a929b719b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
